{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64492f5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Etwas Styling ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ac70d1",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "h1          { color: rgb(226, 0, 26); }\n",
    "h2          { color: rgb(149, 0, 17); }\n",
    ".output_png { display: table-cell;  text-align: center;  vertical-align: middle; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2bc664",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Vorbereitung\n",
    "* [RISE](https://rise.readthedocs.io/en/stable/index.html): Jupyter Notebook Add-On für das Präsentieren von Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70270ed9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install RISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e20046",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<center><img src=\"img/InfluxDB_logo.png\" style=\"margin: 0; width: 45%\"/></center>\n",
    "<br><br>\n",
    "\n",
    "# InfluxDB-Einführung\n",
    "---\n",
    "*DB-Implementierung – Sommersemester 2023 – DHBW Mannheim*\\\n",
    "Frederik Wolter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08247d4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 0. Motivation\n",
    "<br>\n",
    "\n",
    "| time | location | field | value |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| 2023-03-17T00:00:00Z |Mannheim| bees | 23 |\n",
    "| 2023-03-17T00:01:00Z |Frankfurt| ants | 30 |\n",
    "| 2023-03-17T00:05:00Z |Mannheim| bees | 28 |\n",
    "| 2023-03-17T00:06:00Z |Frankfurt| ants | 32 |\n",
    "| 2023-03-17T00:10:00Z |Mannheim| bees | 29 |\n",
    "| 2023-03-17T00:11:00Z |Frankfurt| ants | 40 |\n",
    "| ... | ... | ... | ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6290d1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 0. Motivation – die Zweite\n",
    "<br>\n",
    "\n",
    "| location | field | value |\n",
    "| :--- | :--- | :--- |\n",
    "|Mannheim| bees | 23 |\n",
    "|Frankfurt| ants | 30 |\n",
    "|Mannheim| bees | 28 |\n",
    "|Frankfurt| ants | 32 |\n",
    "|Mannheim| bees | 29 |\n",
    "|Frankfurt| ants | 40 |\n",
    "| ... | ... | ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70516e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 0. Aufbau\n",
    "\\#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eff742",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Time Series Database\n",
    "What is Time Series?\n",
    "\n",
    "A time series is a collection of observations of well-defined data items resulted through repeated measurements over time. Time series data is indexed in time order which is a sequence of data points.\n",
    "\n",
    "\n",
    "\n",
    "What is Time Series Database?\n",
    "\n",
    "Time series database (TSDB) is database system which is optimized for providing time series data and its storage in association with time & value.\n",
    "\n",
    "Time series database consists of measurements or events that are monitored,tracked, refinement of data i.e down sampling & aggregated over time.They can be application monitoring analysis data,server metrics,data about sensors,market trading data,stock exchange data across markets.\n",
    "\n",
    "Time series database is capable of ingesting millions of data points per second providing high level performance.\n",
    "\n",
    "The classic real world example of a time series is stock exchange currency price data.\n",
    "\n",
    "A time series is set of values with a timestamp for each record where time is a meaningful component of the data.\n",
    "\n",
    "TSD are a fast growing segment in the database industry. There are several time series database available, but which is the most popular and the best? Below is the list with its ranking-\n",
    "\n",
    "\\# Bild von Rangilste\n",
    "\n",
    "## Section quelle\n",
    "Time series database\n",
    "\n",
    "According to the official documentation, a time-series database (TSDB) is a database optimized for timestamped or time-series data. Time series data are simply measurements or events that are tracked, monitored, downsampled, and aggregated over time.\n",
    "\n",
    "Furthermore, time-series databases are built to specifically handle this type of data with a timestamp associated with it.\n",
    "\n",
    "Let us consider a few examples to understand this better. The stock market is a very volatile and time-dependent system. It is essential to monitor and store this information along with the timestamp of when the transactions happened. Another example would be gathering sensor data on temperature, pressure, or humidity.\n",
    "\n",
    "These data types require a time associated with each record to help us understand the “trend” or analyze a pattern that changes over time. However, one might ask: Why can’t we just add a column/field called time and keep track of the timestamp when the event occurred.\n",
    "\n",
    "This is possible, but there are two ways to do this: When we get a new record or data for a particular value such as temperature, should we overwrite the previous reading, or should we create a new row in the database?\n",
    "\n",
    "Both methods will provide the current or most recent values. However, we can only analyze the trend of how the system changes over a period of time if we insert a new row. This is what time-series databases are optimized to do.\n",
    "\n",
    "\n",
    "## Seection 2\n",
    "Time-series data\n",
    "\n",
    "Time is a crucial factor when recording data that evolves constantly. Such data enable people to understand the past and predict the future.\n",
    "\n",
    "Time-series data is present in sectors such as business, finance, economics, and health. It can also be found in other scientific fields that tend to show patterns such as trends, seasonal fluctuations, irregular cycles, and variability.\n",
    "\n",
    "Time-series data is gathered from the real world and analyzed by a computer to generate a graphic and analytical output.\n",
    "\n",
    "The results of the data analysis provide us with more information about real-world situations. Data can be collected yearly, quarterly, monthly, daily, or even hourly.\n",
    "Examples of time-series Data\n",
    "\n",
    "    The stock market. This market is highly volatile and time-sensitive. Therefore it is essential to monitor and record the data whenever there are transactions.\n",
    "\n",
    "    In the healthcare industry, time-series data is used to monitor the heart rate of patients taking particular medications. This ensures that their heart rate does not fluctuate too much at any given time.\n",
    "\n",
    "    The weatherman uses time-series data to predict what the temperature will be during different weeks and months.\n",
    "\n",
    "    Retail businesses use time-series data to track their total sales over time.\n",
    "\n",
    "Aspects of time-series Data\n",
    "\n",
    "    Trend: The overall direction of the series.\n",
    "    Seasonality: Occurs when repeated behavior in the data happens at regular intervals.\n",
    "    Cycles: Arise when a series follows a non-seasonal up-and-down trend.\n",
    "    Unexplained variation.\n",
    "\n",
    "\n",
    "## Q3\n",
    "\n",
    "InfluxDB is a Time Serie Database (TSDB)\n",
    "\n",
    "A Time Serie Database (TSDB) is a kind of database that stores values that evolve during time.\n",
    "Typically, a temperature will elvolved each minute. A Time Serie Database will store a key \"temperature\", and then associate an array of timestamp and value that will be filled each minute.\n",
    "\n",
    "This kind of database is designed to store metrics and InfluxDB is probably the most world famous database of this kind.\n",
    "\n",
    "\n",
    "## INflux Data\n",
    "What is a time series database?\n",
    "\n",
    "A time series database (TSDB) is a database optimized for time-stamped or time series data. Time series data are simply measurements or events that are tracked, monitored, downsampled, and aggregated over time. This could be server metrics, application performance monitoring, network data, sensor data, events, clicks, trades in a market, and many other types of analytics data.\n",
    "\n",
    "A time series database is built specifically for handling metrics and events or measurements that are time-stamped. A TSDB is optimized for measuring change over time. Properties that make time series data very different than other data workloads are data lifecycle management, summarization, and large range scans of many records.\n",
    "\n",
    "\n",
    "Why is a time series database important now?\n",
    "\n",
    "Time series databases are not new, but the first-generation time series databases were primarily focused on looking at financial data, the volatility of stock trading, and systems built to solve trading. But financial data is hardly the only application of time series data anymore — in fact, it’s only one among numerous applications across various industries. The fundamental conditions of computing have changed dramatically over the last decade. Everything has become compartmentalized. Monolithic mainframes have vanished, replaced by serverless servers, microservers, and containers.\n",
    "\n",
    "Today, everything that can be a component is a component. In addition, we are witnessing the instrumentation of every available surface in the material world — streets, cars, factories, power grids, ice caps, satellites, clothing, phones, microwaves, milk containers, planets, human bodies. Everything has, or will have, a sensor. So now, everything inside and outside the company is emitting a relentless stream of metrics and events or time series data.\n",
    "\n",
    "This means that the underlying platforms need to evolve to support these new workloads — more data points, more data sources, more monitoring, more controls. What we’re witnessing, and what the times demand, is a paradigmatic shift in how we approach our data infrastructure and how we approach building, monitoring, controlling, and managing systems. What we need is a performant, scalable, purpose-built time series database.\n",
    "\n",
    "\n",
    "What distinguishes the time series workload?\n",
    "\n",
    "Time series databases have key architectural design properties that make them very different from other databases. These include time-stamp data storage and compression, data lifecycle management, data summarization, ability to handle large time series dependent scans of many records, and time series aware queries.\n",
    "\n",
    "downsample\n",
    "\n",
    "For example: With a time series database, it is common to request a summary of data over a large time period. This requires going over a range of data points to perform some computation like a percentile increase this month of a metric over the same period in the last six months, summarized by month. This kind of workload is very difficult to optimize for with a distributed key value store. TSDB’s are optimized for exactly this use case giving millisecond level query times over months of data. Another example: With time series databases, it’s common to keep high precision data around for a short period of time. This data is aggregated and downsampled into longer term trend data. This means that for every data point that goes into the database, it will have to be deleted after its period of time is up. This kind of data lifecycle management is difficult for application developers to implement on top of regular databases. They must devise schemes for cheaply evicting large sets of data and constantly summarizing that data at scale. With a time series database, this functionality is provided out of the box.\n",
    "\n",
    "\n",
    "Independent ranking of top 15 time series databases\n",
    "\n",
    "Time series databases are the fastest growing segment in the database industry. But which time series database is the best and most popular? There are many ways of determining popularity, but an independent website, DB-Engines, ranks databases based on search engine popularity, social media mentions, job postings, and technical discussion volume. (Read their full methodology). Here are the current results:\n",
    "\n",
    "    InfluxDB\n",
    "    Kdb+\n",
    "    Prometheus\n",
    "    Graphite\n",
    "    TimescaleDB\n",
    "    DolphinDB\n",
    "    RRDTool\n",
    "    OpenTSDB\n",
    "    Apache Druid\n",
    "    TDengine\n",
    "    GridDB\n",
    "    QuestDB\n",
    "    Fauna\n",
    "    Amazon Timestream\n",
    "    VictoriaMetrics\n",
    "\n",
    "To see trends over time, the following graphic shows the top 10 time series databases and their historical changes:\n",
    "\n",
    "\\# JAN-2023-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7628995a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. InfluxDB-Universum\n",
    "InfluxDB\n",
    "\n",
    "InfluxDB is the most popular open-source time-series database, created by a company called Influx data in 2013. InfluxDB provides APIs for various popular programming languages such as Python, Golang, Java, etc.\n",
    "\n",
    "\n",
    "InfluxDB overview\n",
    "\n",
    "InfluxDB is an open-source time-series database written in Go and developed by Influx data.\n",
    "\n",
    "It is designed to store and retrieve time-series data quickly. Moreover, it works seamlessly with the right platform to collect, store and analyze data.\n",
    "\n",
    "\n",
    "What is InfluxDB\n",
    "\n",
    "InfluxDB is an open source Time Serie Database (TSDB).\n",
    "It is specialized in operations like monitoring, application metrics, Internet of Things (IoT) sensors data and real-time analytics.\n",
    "It is mainly written in Go language and is designed for high-performance and high-efficiency storage.\n",
    "It can store thousands of data points every second making it perfect for industrial grade applications.\n",
    "\n",
    "Once stored, data can be queried and analyzed using the \"Flux\" language.\n",
    "This language is an integral part of InfluxDB and permits advanced data manipulations to analyze your data in an incredible depth.\n",
    "\n",
    "\n",
    "InfluxData, the company behind InfluxDB\n",
    "\n",
    "InfluxDB has been created in 2012 by the company InfluxData (named Errplane at this time).\n",
    "It has been backed by Y Combinator startup accelerator that launched companies like Airbnb, Dropbox, PagerDuty, Coinbase, Stripe or Twitch.\n",
    "\n",
    "Overt the years InfluxData has been trusted by many companies and investors and has raised a total of $119 million since its creation.\n",
    "\n",
    "Its HQ is in San Francisco (California, United States) but, as a lot of company nowadays, lots of its employees are working remotely all over the world.\n",
    "\n",
    "\n",
    "# Wikipedia\n",
    "InfluxDB ist ein Open Source Datenbankmanagementsystem (DBMS), speziell für Zeitreihen (engl. time series). Es wird von der Firma InfluxData entwickelt und vertrieben. \n",
    "Entwickler \tInfluxData\n",
    "Erscheinungsjahr \t24. September 2013\n",
    "Aktuelle Version \t2.5.1[1]\n",
    "(3. November 2022)\n",
    "Betriebssystem \tLinux, FreeBSD, macOS, Windows\n",
    "Programmiersprache \tGo\n",
    "Kategorie \tDBMS\n",
    "Lizenz \tOpen Source (MIT-Lizenz) bzw. proprietär \n",
    "\n",
    "\n",
    "## INflux Data\n",
    "What makes InfluxDB time series database unique?\n",
    "\n",
    "InfluxDB was built from the ground up to be a purpose-built time series database; i.e., it was not repurposed to be time series. Time was built-in from the beginning. InfluxDB is part of a comprehensive platform that supports the collection, storage, monitoring, visualization and alerting of time series data. It’s much more than just a time series database.\n",
    "\n",
    "The whole InfluxData platform is built from an open source db core. InfluxData is an active contributor to the Telegraf, InfluxDB, Chronograf  and Kapacitor (TICK) projects — the “I,C,K” from the TICK Stack is being collapsed into a single binary in InfluxDB 2.0 — as well as selling InfluxDB Enterprise and InfluxDB Cloud on this open source core. The InfluxDB data model is quite different from other time series solutions like Graphite, RRD, or OpenTSDB. InfluxDB has a line protocol for sending time series data which takes the following form: measurement-name tag-set field-set timestamp. The measurement name is a string, the tag set is a collection of key/value pairs where all values are strings, and the field set is a collection of key/value pairs where the values can be int64, float64, bool, or string. The measurement name and tag sets are kept in an inverted index which make lookups for specific series very fast. For example, if we have CPU metrics:\n",
    "\n",
    "cpu,host=serverA,region=uswest idle=23,user=42,system=12 1464623548s\n",
    "\n",
    "Timestamps in InfluxDB can be second, millisecond, microsecond, or nanosecond precision. The micro and nanosecond scales make InfluxDB a good choice for use cases in finance and scientific computing where other solutions would be excluded. Compression is variable depending on the level of precision the user needs. On disk, the data is organized in a columnar style format where contiguous blocks of time are set for the measurement, tagset, field. So, each field is organized sequentially on disk for blocks of time, which make calculating aggregates on a single field a very fast operation. There is no limit to the number of tags and fields that can be used.\n",
    "\n",
    "Other time series solutions don’t support multiple fields, which can make their network protocols bloated when transmitting data with shared tag sets. Most other time series solutions only support float64 values, which means the user is unable to encode additional metadata along with the time series. Even OpenTSDB and KairosDB, which support tags (unlike Graphite and RRD), have limitations on the number of tags that can be used. At around 5 to 6 tags, the user will start seeing hot spots within their cluster of HBase or Cassandra machines.\n",
    "\n",
    "InfluxDB doesn’t have this limitation because the InfluxDB data model is designed for time series specifically. It pushes the developer in the right direction to get good performance out of the database by indexing tags and keeping fields unindexed. It’s flexible in that many data types are supported, and the user can have many fields and tags. Because of all these factors, a purpose-built time series database like InfluxDB is the best solution for working with time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54187e78",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2.# TICK-Stack\n",
    "\n",
    "What is the TICK Stack?\n",
    "\n",
    "The TICK Stack is an acronym that denotes for a platform of open source tools built to collect, store, graphing, and providing alerts on time series data incredibly easy and efficiently. “I” in TICK is “INFLUXDB”. TICK stack contains various components which are:\n",
    "\n",
    "TELEGRAF: Telegraf’s provides collection of metrics and metrics collection agent that is used to collect and send metrics to InfluxDB.\n",
    "\n",
    "InfluxDB:\n",
    "Influx DB is an open source time series database written in Go language which is developed by InfluxData. It is optimized for high-availability retrieval of data,faster and storage of time series data in fields such as operations monitoring, application metrics, IoT sensor data, and real-time analytics.\n",
    "\n",
    "InfluxDB is a high performance Time Series Database which can store data ranging from hundreds of thousands of points per second. The InfluxDB is a SQL-kind of query language which was built specifically for time series data.\n",
    "\n",
    "CHRONOGRAF: It’s a whole TICK stack UI used to setup graphs and dashboard of data in InfluxDB and integrate the Kapacitor alerts\n",
    "\n",
    "KAPACITOR: It is used to break/crunch time series data into action alerts and send these alerts across to several products like Slack and PagerDuty. Kapacitor is a metrics,event processing and alerting system application.The entire TICK Stack is interoperable,with each component providing significant value as a standalone application.\n",
    "\n",
    "\\# bild von TICK Stack\n",
    "\n",
    "++ Grafana\n",
    "https://www.influxdata.com/how-to-visualize-time-series-data/\n",
    "\n",
    "https://www.section.io/engineering-education/introduction-to-influxdb/select.png\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df51480",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2.# Anwendung\n",
    "Examples where Influxdb can be used\n",
    "    System Monitoring like disk ops.\n",
    "    Collection of IoT data.\n",
    "    Heart rate data\n",
    "    Logging\n",
    "    Tracing (what took more time among components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a3046",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. InfluxDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98b0b0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.# Formen von InfluxDB\n",
    "InfluxDB OSS CLI\n",
    "InfluxDB OSS Docker\n",
    "+ InfluxDB UI\n",
    "InfluxDB Cloud\n",
    " \n",
    "InfluxDB API client libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472015c9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.# Begriffe\n",
    "Measurement, Tags, Fields & Points?\n",
    "\\# tbl?\n",
    "\n",
    "InfluxDB requires a certain format for inserting data. Every record or row is referred to as a “point” and has 4 elements:\n",
    "\n",
    "    measurement: The name of the measurement and requires one measurement per point. This is similar to the “table” in a conventional database system such as SQL.\n",
    "\n",
    "    tag: This is a key-value pair that corresponds to a row in the table.\n",
    "\n",
    "    field: The field is an optional argument and is a set of key-value pairs that store information.\n",
    "\n",
    "    timestamp: This is also an optional argument that tells us the time at which the data was inserted. If the timestamp is not specified, InfluxDB automatically stores the current time as the timestamp.\n",
    "\n",
    "For more information on these elements, have a look at the official documentation.\n",
    "\n",
    "\n",
    "\n",
    "## \\#\n",
    "\n",
    "In this data example, we have some important concepts:\n",
    "Term\tDefinition\tExample Use Case\n",
    "measurement\tPrimary filter for the thing you are measuring.\tSince we are measuring the sample census of insects, our measurement is \"census\".\n",
    "tag\tKey-value pair to store metadata about your fields.\tWe are storing the \"location\" of where each census is taken. Tags are indexed and should generally be bounded (i.e. only a few cities).\n",
    "field\tKey-value pair that stores the actual data you are measuring.\tWe are storing the insect \"species\" and \"count\" as the key-value pair. Fields are not indexed and can be stored as integers, floats, strings, or booleans.\n",
    "\n",
    "These concepts are important in building your time-series schema. Now, let's write this data into our bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc86b48",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.# Flux\n",
    "\n",
    "Using Flux to query Data from the InfluxDB Cloud\n",
    "\n",
    "Flux is a functional, extensible, and composable data scripting language designed for time-series data.\n",
    "\n",
    "It queries, analyzes, and acts on data, then visualizes the results. It has support for querying data from various sources, including CSV and SQL.\n",
    "\n",
    "Flux creates some composable functions to use as building blocks. A Flux query retrieves data from the data source, filters it based on time or column values, processes the data, and returns results.\n",
    "\n",
    "In InfluxDB, we have buckets that act as databases. To create a bucket, navigate on the left side and select Load Data, as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4ebda",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.# Retention\n",
    "How to avoid disk space saturation\n",
    "\n",
    "InfluxDB is a time series database. Such database typically receive a lot of metrics and doesn't delete them. This means that your database will grow infinitely.\n",
    "Unfortunately, you don't have infinite disk space.\n",
    "\n",
    "To avoid a disk space saturation, InfluxDB provides two solutions.\n",
    "\n",
    "The first one consists in deleting the data prior to a defined date. For example, you will define that data older than 365 days have to be deleted.\n",
    "This is called \"retention\" and you will find more informations about it below.\n",
    "\n",
    "The second one is to downsample your data. Imagine you store a temperature every second. It is great to have a live view of the temperature but you probably don't need to keep a 1 second resolution for months.\n",
    "You can, for example, downsample this metric like this:\n",
    "\n",
    "    keep temperature with 1 second resolution for the last 5 minutes.\n",
    "    keep maximums, minimums and averages temperatures with 1 minute resolution for the last 24 hours.\n",
    "    keep maximums, minimums and averages temperatures with 1 hour resolution for the rest of the data.\n",
    "\n",
    "Using retention, you will be able to keep your data for a long period without having to store terabytes of data.\n",
    "You will find more informations about downsample on the official documentation.\n",
    "\n",
    "\n",
    "\n",
    "Handling InfluxDB retention\n",
    "\n",
    "Per default, InfluxDB will store your data and never delete them.\n",
    "While this seems normal for a classical database, it is not for a time series database type.\n",
    "Indeed, a time series database is supposed to delete its oldest data to avoid unlimited growth.\n",
    "\n",
    "For example, if you store a battery voltage, the data is probably interesting for few days but not for years.\n",
    "\n",
    "To avoid any disk space saturation, this is very important that you configure a retention period for each of your buckets.\n",
    "\n",
    "To do this, go to your InfluxDB WEB UI, click on \"Data\", then \"Buckets\" and click on \"Settings\" closed to the bucket you want to configure.\n",
    "Then select \"Delete data older than\" and select the retention you desire.\n",
    "\n",
    "⚠️ Don't forget that you will loose data older than this retention period!\n",
    "\n",
    "Note that data are organized in shards. Shards with outdated data will be deleted.\n",
    "But a shard which contains outdated and non outdated data will not be deleted.\n",
    "By default, when no retention has been defined, a shard contains 7 days of data. That means that when you will define a retention period, almost 7 days of outdated data will be kept, in addition to your fresh data.\n",
    "\n",
    "You will find more informations about shards on the official documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9075cb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.# Internals\n",
    "https://docs.influxdata.com/influxdb/v2.6/reference/internals/storage-engine/#time-series-index-tsi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8b69c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Bewertung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7b62c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.# Unterschied zu relationalen SQL DBs\n",
    "Differences between InfluxDB and relational/SQL databases\n",
    "A Time Serie Database is totally different from a relational database (like MySQL or PostgreSQL) as it doesn't create relationships between data.\n",
    "Relational database are perfect to store data like users and messages. In such databases, you will link messages to users, so you can query it by asking \"give me all the messages from this user that have been sent today\".\n",
    "Time Serie Databases will not be able to do this kind of job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72383762",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.# Unterschied zu noSQL DBs\n",
    "Differences between InfluxDB and NoSQL databases\n",
    "A NoSQL database (like MongoDB or OpenSearch) stores data like documents. It is an association of multiple data, like a user name, its birthday and its email.\n",
    "NoSQL databases are competitors of SQL relational databases and, as such, are not designed to store metrics data like InfluxDB does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688e5e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.# Nachteile von InfluxDB\n",
    "When to not use InfluxDB\n",
    "If you want to store documents or data that are not metrics, like users informations, messages or PDF documents, then InfluxDB is not the good choice.\n",
    "In that case we recommend to have a look at PostgreSQL, MySQL or OpenSearch databases.\n",
    "Also, if your goal is to store metrics for servers or network equipments (like switches or routers), you should probably have a look at solutions like Prometheus that are dedicated for this purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17194b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.# Vorteile von InfluxDB\n",
    "Why use InfluxDB?\n",
    "Faster time\n",
    "Deep insights and analytics\n",
    "Efficient in developer productivity- InfluxDB is — storage,ingest, query, and visualization — which is now accessible via unified API.\n",
    "UI dashboards to view the data like Grafana,Chronograf\n",
    "Easy-to-build, easy-to-share templates- through influxDb templates\n",
    "\n",
    "\n",
    "When to use InfluxDB\n",
    "\n",
    "InfluxDB is perfect if you want to store, query and analyze metrics data, like IoT sensors, monitoring records or applications metrics.\n",
    "\n",
    "Typically, IoT devices that are connected using WiFi, 5G, Sigfox or LoRa networks send their sensors values (temperatures, 3 axis accelerometer, GPS coordinates, etc...) at regular intervals. These data are enhanced with health data like battery voltage and network reception.\n",
    "There IoT devices will send all these data at regular intervals to InfluxDB that will store them in an efficient way.\n",
    "\n",
    "With its high performances API, InfluxDB can ingest thousands of data per seconds with no problem.\n",
    "And with its advanced \"Flux\" language, you will be able to query and analyze these data in few lines.\n",
    "\n",
    "\n",
    "What makes InfluxDB so great\n",
    "\n",
    "InfluxDB is an awesome product for these reasons:\n",
    "\n",
    "    It perfectly handles telemetry data like monitoring, applications metrics or IoT sensors\n",
    "    Data are automatically compressed to manage disk occupation efficiently\n",
    "    Downsampling tasks run automatically to reduce disk usage and increase query performances\n",
    "    Retention policies can be applied to automatically delete old data after a defined amount of time\n",
    "    Flux language is super porwerful and permits to analyze in depth stored data\n",
    "    InfluxDB WEB UI gives the ability to create beautiful dasbboards in minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd8ef5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Beispiel\n",
    "Verwendung von `InfluxDB Cloud` in Kombination mit Python API\n",
    "\n",
    "### [InfluxDB Cloud](https://eu-central-1-1.aws.cloud2.influxdata.com/)\n",
    "* User Interface\n",
    "* Side Bar\n",
    "* Hierarchie (Profile, Org, Bucket ...)\n",
    "\\\n",
    "\\#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1b8bd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.1 Reqirements – Packages\n",
    "`Python 3` und folgende Packages:\n",
    "1. [influxdb-client](https://github.com/influxdata/influxdb-client-python) für die Verbindung zur InfluxDB.\n",
    "2. [pandas](https://pandas.pydata.org/) für die Organisation der Datenausgabe bei Abfragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98db96",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install influxdb-client\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea758a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.1 Reqirements – Tokens\n",
    "`InfluxDB Cloud` verwendet `Token` für API-Zugang.<br><br><br>\n",
    "Verwendung als Umgebungsvariable in Jupyter Notebook durch:\n",
    "```python\n",
    "%env INFLUXDB_TOKEN=INSERT_TOKEN_HERE\n",
    "```\n",
    "Alternativ im Terminal durch:\n",
    "```bash\n",
    "export INFLUXDB_TOKEN=INSERT_TOKEN_HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed706a7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run config.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d36dac2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.1 Reqirements – Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e7ea9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "from influxdb_client import WritePrecision\n",
    "from datetime import datetime \n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9191cc25",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.2 Script – Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a4932",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "url   = \"https://eu-central-1-1.aws.cloud2.influxdata.com\"\n",
    "token = os.environ[\"INFLUXDB_TOKEN\"]\n",
    "org   = \"DB-Impl\"\n",
    "\n",
    "client = InfluxDBClient(url=url, token=token, org=org)\n",
    "\n",
    "# do stuff ...\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5a246",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.3 Script – Write\n",
    "Daten in Bucket schreiben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "url   = \"https://eu-central-1-1.aws.cloud2.influxdata.com\"\n",
    "token = os.environ[\"INFLUXDB_TOKEN\"]\n",
    "org   = \"DB-Impl\"\n",
    "bucket= \"Demo\"\n",
    "\n",
    "with InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "    with client.write_api(write_options=SYNCHRONOUS) as write_api:\n",
    "        p = Point(\"weather\") \\\n",
    "                .tag(\"location\", \"Mannheim\") \\\n",
    "                .field(\"temperature\", 25.9) \\\n",
    "               #.time(datetime.utcnow(), WritePrecision.MS)\n",
    "        write_api.write(org=org, bucket=bucket, record=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e321b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url   = \"https://eu-central-1-1.aws.cloud2.influxdata.com\"\n",
    "token = os.environ[\"INFLUXDB_TOKEN\"]\n",
    "org   = \"DB-Impl\"\n",
    "bucket= \"Demo\"\n",
    "\n",
    "with InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "    with client.write_api(write_options=SYNCHRONOUS) as write_api:\n",
    "        p = Point(\"weather\") \\\n",
    "                .tag(\"location\", \"Mannheim\") \\\n",
    "                .field(\"humidity\", 90) \\\n",
    "               #.time(datetime.utcnow(), WritePrecision.MS)\n",
    "        write_api.write(org=org, bucket=bucket, record=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e23bb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.3 Script – Write Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb5071",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "import time\n",
    "\n",
    "url   = \"https://eu-central-1-1.aws.cloud2.influxdata.com\"\n",
    "token = os.environ[\"INFLUXDB_TOKEN\"]\n",
    "org   = \"DB-Impl\"\n",
    "bucket= \"Demo\"\n",
    "\n",
    "with InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "    with client.write_api(write_options=SYNCHRONOUS) as write_api:\n",
    "        for i in range(60):\n",
    "            v = round(uniform(25, 28), 2)\n",
    "            p = Point(\"weather\").tag(\"location\", \"Mannheim\").field(\"temperature\", v)\n",
    "            \n",
    "            write_api.write(org=org, bucket=bucket, record=p)\n",
    "            \n",
    "            print(\".\", end='')\n",
    "            time.sleep(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec4eec9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5.4 Script – Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59148f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "url   = \"https://eu-central-1-1.aws.cloud2.influxdata.com\"\n",
    "token = os.environ[\"INFLUXDB_TOKEN\"]\n",
    "org   = \"DB-Impl\"\n",
    "bucket= \"Demo\"\n",
    "\n",
    "with InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "    query_api = client.query_api()\n",
    "    tables = query_api.query('from(bucket: \"Demo\") |> range(start: -1d)')\n",
    "\n",
    "    for table in tables:\n",
    "        for record in table.records:\n",
    "            print(str(record[\"_time\"]) + \" - \" + record.get_measurement()\n",
    "                + \" \" + record.get_field() + \"=\" + str(record.get_value()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbec7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url   = \"https://eu-central-1-1.aws.cloud2.influxdata.com\"\n",
    "token = os.environ[\"INFLUXDB_TOKEN\"]\n",
    "org   = \"DB-Impl\"\n",
    "bucket= \"Demo\"\n",
    "\n",
    "with InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "    query_api = client.query_api()\n",
    "    query = '''from(bucket:\"Demo\")\n",
    "                |> range(start: -1h)\n",
    "                |> keep(columns: [\"_time\", \"_measurement\", \"location\", \"_field\", \"_value\"])'''    \n",
    "    result = query_api.query_data_frame(query=query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87518bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url   = \"https://eu-central-1-1.aws.cloud2.influxdata.com\"\n",
    "token = os.environ[\"INFLUXDB_TOKEN\"]\n",
    "org   = \"DB-Impl\"\n",
    "bucket= \"Demo\"\n",
    "\n",
    "with InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "    query_api = client.query_api()\n",
    "    query = '''from(bucket:\"Demo\")\n",
    "                |> range(start: -1d)\n",
    "                |> pivot(rowKey: [\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "                |> keep(columns: [\"_time\", \"_measurement\", \"location\", \"temperature\", \"humidity\"])'''  \n",
    "    result = query_api.query_data_frame(query=query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b60ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flightsql import FlightSQLClient\n",
    "\n",
    "query = \"\"\"SELECT *\n",
    "FROM 'census'\n",
    "WHERE time >= now() - interval '24 hours'\n",
    "AND ('bees' IS NOT NULL OR 'ants' IS NOT NULL)\"\"\"\n",
    "\n",
    "# Define the query client\n",
    "query_client = FlightSQLClient(\n",
    "  host = \"eu-central-1-1.aws.cloud2.influxdata.com\",\n",
    "  token = os.environ.get(\"INFLUXDB_TOKEN\"),\n",
    "  metadata={\"bucket-name\": \"Demo\"})\n",
    "\n",
    "# Execute the query\n",
    "info = query_client.execute(query)\n",
    "reader = query_client.do_get(info.endpoints[0].ticket)\n",
    "\n",
    "# Convert to dataframe\n",
    "data = reader.read_all()\n",
    "df = data.to_pandas().sort_values(by=\"time\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query script\n",
    "query_api = write_client.query_api()\n",
    "query = 'from(bucket:\"Demo\")\\\n",
    "|> range(start: -10h)'\n",
    "result = query_api.query(org=org, query=query)\n",
    "results = []\n",
    "for table in result:\n",
    "    for record in table.records:\n",
    "        results.append((record.get_field(), record.get_value()))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query script\n",
    "query_api = write_client.query_api()\n",
    "query = 'from(bucket:\"Demo\")\\\n",
    "|> range(start: -10h)\\\n",
    "|> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\\\n",
    "|> drop(columns: [\"result\", \"_start\", \"_stop\"])'\n",
    "result = query_api.query_data_frame(org=org, query=query)\n",
    "#result.drop(columns=[\"result\", \"_start\", \"_stop\"], inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3524dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ende\n",
    "[github.com/FrederikWolter/InfluxDB-Introduction](https://github.com/FrederikWolter/InfluxDB-Introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b7334",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quellen – Inhalt\n",
    "* Allgemein\n",
    "  * https://wearecommunity.io/communities/india-java-user-group/articles/891\n",
    "  * https://www.section.io/engineering-education/introduction-to-influxdb/\n",
    "  * https://www.section.io/engineering-education/visualize-time-series-data-with-chart-js/\n",
    "  * https://www.stackhero.io/en/services/InfluxDB/documentations/Introduction\n",
    "  * https://www.stackhero.io/en/services/InfluxDB/documentations/Getting-started#how-to-avoid-disk-space-saturation\n",
    "  * https://de.wikipedia.org/wiki/InfluxDB\n",
    "* Time Series Database\n",
    "  * https://www.influxdata.com/time-series-database/\n",
    "* Dokumentation\n",
    "  * https://docs.influxdata.com/influxdb/cloud/\n",
    "  * https://docs.influxdata.com/influxdb/v2.6/\n",
    "  * https://docs.influxdata.com/influxdb/v1.8/concepts/glossary/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d78e5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quellen – Abbildungen\n",
    "* https://dbdb.io/media/logos/InfluxDB.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e8381",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* https://docs.influxdata.com/influxdb/v2.6/get-started/ ###\n",
    "<br><br>\n",
    "* https://portal.influxdata.com/downloads/\n",
    "* https://eu-central-1-1.aws.cloud2.influxdata.com/ ##\n",
    "* https://www.influxdata.com/influxdb-cloud-pricing/ ##\n",
    "* https://www.influxdata.com/time-series-platform/telegraf/ ##\n",
    "* https://www.influxdata.com/time-series-platform/chronograf/ ##\n",
    "* https://www.influxdata.com/time-series-platform/kapacitor/ ##\n",
    "* https://www.influxdata.com/products/influxdb-overview/ ## \n",
    "<br><br>\n",
    "* https://docs.influxdata.com/influxdb/cloud/query-data/execute-queries/query-sample-data/#add-sample-data ##\n",
    "* https://docs.influxdata.com/resources/videos/using-pandas-dataframes-in-influxdb-with-python/ ##\n",
    "* https://www.influxdata.com/blog/getting-started-with-influxdb-and-pandas/ ##\n",
    "<br><br>\n",
    "* https://docs.influxdata.com/influxdb/cloud/query-data/get-started/transform-data/ ##\n",
    "* https://docs.influxdata.com/resources/videos/pivots-in-flux/ ##\n",
    "* https://docs.influxdata.com/influxdb/cloud/api-guide/client-libraries/python/ ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4022ad4",
   "metadata": {},
   "source": [
    "https://influx-testdata.s3.amazonaws.com/air-sensor-data-annotated.csv\n",
    "\n",
    "https://docs.influxdata.com/influxdb/v2.6/reference/sample-data/\n",
    "https://docs.influxdata.com/influxdb/v2.6/process-data/manage-tasks/create-task/ \\\n",
    "-> python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd252d9f",
   "metadata": {},
   "source": [
    "# OLD \\#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586c244",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2.1 Data Understanding – DB Timetable\n",
    "\n",
    "* API des Deutschen Bahn API-Marketplace\n",
    "\n",
    "* `/station/{pattern}`\n",
    "```xml\n",
    "<station meta=\"518342\" name=\"Mannheim Hbf\" eva=\"8000244\" p=\"...\" ...=\"\" />\n",
    "```\n",
    "\n",
    "* `/fchg/{evaNo}` \\\n",
    "  viele schlecht dokumentierte Daten über Fahrplan-Abweichungen u. a.\n",
    "    * Zugtyp, Zugnummer, Baustellen, _Durchsagen?_\n",
    "    * **geänderte** Gleise, Ankünfte, Abfahrten, Ausfälle\n",
    "\n",
    "    <div class=\"alert alert-danger\">\n",
    "        <b>Achtung:</b> keine Plan-Daten (andere API) -> ungeignet für Verspätungsbestimmung\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76cb1ba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.1 Data Preparation – Zug\n",
    "\n",
    "* Speichern als **einzelne** Ankunft/Abfahrt\n",
    "\n",
    "* Hinzufügen von `eva` und `board_type`\n",
    "\n",
    "* Parsen zu `JSON`:\n",
    "\n",
    "    ```json\n",
    "    {\n",
    "        \"timestamp\": \"2022-11-03T17:48:00+01:00\",\n",
    "        \"eva\": 8000244,\n",
    "        \"board_type\": \"arr\",\n",
    "        \"con_line\": \"725\",\n",
    "        \"con_type\": \"ICE\",\n",
    "        \"delay\": 26\n",
    "    }\n",
    "    ```\n",
    "    \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Info:</b> <code>delay</code> \"cancel\" wird als <code>-1</code> dargestellt\n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b3be8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.1 Modeling – Datenbank\n",
    "* Als Datenbank wurde eine **MongoDB** auf einem Debian-Server eingerichtet\n",
    "* für dieses Projekt angelegt\n",
    "  * _Datenbank_: `DBWeather`\n",
    "  * _Collections_: `data_train`, `data_weather`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb92ae0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.3 Modeling – Ausfürhung\n",
    "\n",
    "* **Python-Skripte** durch Debian-Server via `cronjob` alle **30 Min.** ausgeführt\n",
    "  \n",
    "* Bei Ausführung wird ein **Log** erstellt:\n",
    "\n",
    "    <pre style=\"font-size: 0.8em !important;\"><code style=\"max-height: none;\">  2022-11-03 19:00:01,408 INFO  weather: Start main_weather execution ...\n",
    "    2022-11-03 19:00:01,708 INFO  weather: Result lat=50.05 lon=8.6 has 25 elements\n",
    "    2022-11-03 19:00:01,824 INFO  weather: Result lat=49.5 lon=8.48 has 25 elements\n",
    "    2022-11-03 19:00:01,844 INFO  weather: finished: 0 inserted, 2 updated, 48 unchanged\n",
    "    2022-11-03 19:00:01,844 INFO  weather: ###########################################\n",
    "    2022-11-03 19:00:01,915 INFO  train: Start main_train execution ...\n",
    "    2022-11-03 19:00:01,917 INFO  train: Result eva=8000105 type=arr has 690 lines\n",
    "    2022-11-03 19:00:02,493 INFO  train: Result eva=8000105 type=dep has 672 lines\n",
    "    2022-11-03 19:00:02,938 INFO  train: Result eva=8000244 type=arr has 291 lines\n",
    "    2022-11-03 19:00:03,233 INFO  train: Result eva=8000244 type=dep has 264 lines\n",
    "    2022-11-03 19:00:03,301 INFO  train: finished: 295 inserted, 119 updated, 225 unchanged\n",
    "    2022-11-03 19:00:03,301 INFO  train: ###########################################</code></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab0dcf",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# plot config\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"figure.dpi\"] = 200\n",
    "mpl.rcParams[\"figure.figsize\"] = [10.00, 4.00]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
